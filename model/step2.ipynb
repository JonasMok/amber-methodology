{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. Extraction of features & modelling\n",
    "\n",
    "Here I'll convert each subimage (each segment/superpixel) from different satellite images to long vector of features, with a help of (magic!) [Keras](https://keras.io/) library and model called [ResNet50](https://keras.io/applications/#resnet50), pretrained on ImageNet dataset. \n",
    "\n",
    "Note, directory __\"./datasets/positive/\"__ should contain examples of segments with amber mining, and \n",
    "directory __\"./datasets/negative/\"__ should contain segments without such patterns.\n",
    "\n",
    "It's an example of [\"transfer learning\"](https://en.wikipedia.org/wiki/Transfer_learning): ResNet50 is trained on images from categories such as \"dog\", \"car\", \"tree\", but I'll use quite different satellite images with \"natural\" objects such as trees or agriculture fields, as an input. \n",
    "\n",
    "Anyway, ResNet50 neural network allow me to obtain the values from its penultimate layer  as features for classifier. It's possible because ResNet, even pretrained with quite different pictures, has learn to find a representation of *any* image as a high-dimencional vector with the same length (2048 in this case). \n",
    "\n",
    "There are many ways to improve this step (i.e to train ResNet50 for more specific categories/images such as OSM labels and corresponding satellite images). But why bother if you could achieve result which is good enough, without additional complications? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce code below with tolerable time of execution, you have to install CUDA drivers for your GPU (if you have one).  OR just run next cell and after that jump to cell with such code (unzip file features_backup.csv.zip, first):\n",
    "```python \n",
    "df = pd.read_csv(\"features_backup.csv\")\n",
    "```\n",
    "and load precalculated features. Also, you should do this if you don't have an images in \"negative\" and \"positive\" directories.\n",
    "\n",
    "\n",
    "NOTE: This is short, educational version for \"how to create a model\" notebook. More detailed version, with explanation of my process of \"visual debugging\" of the model, one could [find here](visually_debug_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from os import listdir, environ\n",
    "from os.path import isfile, join\n",
    "\n",
    "# to allocate only one GPU for this notebook (I have two on board)\n",
    "# environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\" \n",
    "\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, f1_score, recall_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_img_path =  \"./datasets/positive/\"  # where to find positive examples (images with amber extraction footprints ) \n",
    "negative_img_path =  \"./datasets/negative/\"  # where to find negative examples \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of positive and negative filenames\n",
    "positive_files = [join(positive_img_path, f) for f in listdir(positive_img_path) if isfile(join(positive_img_path, f))] # list of image names with positive examples\n",
    "negative_files = [join(negative_img_path, f) for f in listdir(negative_img_path) if isfile(join(negative_img_path, f))] # list of image names with negative examples\n",
    "\n",
    "resnet = ResNet50(weights='imagenet', include_top=False) # load ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250/250 [==============================] - 5s 22ms/step\n",
      "900/900 [==============================] - 13s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_features(img_paths, batch_size=64):\n",
    "    \"\"\" This function extracts image features for each image in img_paths using ResNet50 penultimate layer.\n",
    "        Returned features is a numpy array with shape (len(img_paths), 2048).\n",
    "    \"\"\"\n",
    "    global resnet\n",
    "    n = len(img_paths) # num of images in img_paths\n",
    "    img_array = np.zeros((n, 224, 224, 3))\n",
    "    \n",
    "    for i, path in enumerate(img_paths):\n",
    "        img = image.load_img(path, target_size=(224, 224))  # load and scale each image to 224x224 size\n",
    "        img = image.img_to_array(img)\n",
    "        img = preprocess_input(img)\n",
    "        img_array[i] = img\n",
    "    \n",
    "    X = resnet.predict(img_array, batch_size=batch_size, verbose=1)\n",
    "    X = X.reshape((n, 2048))\n",
    "    return X\n",
    "\n",
    "# features for our two types of labels\n",
    "positives_ = extract_features(positive_files)\n",
    "negatives_ = extract_features(negative_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the dataframe: (1150, 2050)\n"
     ]
    }
   ],
   "source": [
    "# Create dataframe from two types of features, for positive images(with amber mining footprints) and \n",
    "# negative(without mining) \n",
    "\n",
    "def create_df(feature_vectors, label, img_paths):\n",
    "    \"\"\" create panda df. Each row in df consists of features, label and path to corresponding image \"\"\"\n",
    "    feat_cols = [ 'feature'+str(i) for i in range(feature_vectors.shape[1]) ] # column names for elements of feature vector\n",
    "    df = pd.DataFrame(feature_vectors,columns=feat_cols)\n",
    "    df['label'] = label # add column with labels\n",
    "    df['path'] = img_paths # add column with img paths\n",
    "    return df\n",
    "\n",
    "df1 = create_df(positives_, \"positive\", positive_files)\n",
    "df2 = create_df(negatives_, \"negative\", negative_files)\n",
    "df = df1.append(df2)\n",
    "print 'Size of the dataframe: {}'.format(df.shape)\n",
    "\n",
    "# in case you want to save features for later use, uncomment line below\n",
    "# df.to_csv(\"features_backup.csv\",  index = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IGNORE this cell if you successfully run all cells above.\n",
    "\n",
    "### START HERE if you don't want to calculate features from images: instead, get it from backup\n",
    "df = pd.read_csv(\"features_backup.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time for the modelling!\n",
    "Here we'll try couple of different models for our labeled features, extracted from images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:,0:2048].values  # numeric feature values for each image\n",
    "Y = df.iloc[:, 2048].values   # labels for each image\n",
    "tiles = df[\"path\"].values     # path to image files \n",
    "\n",
    "# split each list to test and train parts \n",
    "X_train, X_test, Y_train, Y_test, tiles_train, tiles_test = train_test_split(X, Y, tiles, test_size = 0.3, \n",
    "                                                                             random_state = 43)\n",
    "\n",
    "# Just print all evaluation scores from one place\n",
    "def evaluate(Y_test, Y_pred):\n",
    "    accuracy = accuracy_score(Y_test, Y_pred)\n",
    "    print(\"\\nModel Performance\")\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    print(confusion_matrix(Y_test, Y_pred))\n",
    "    print(\"\\nprecision:\")\n",
    "    print(precision_score(Y_test, Y_pred, pos_label = \"positive\"))\n",
    "    print(\"\\nrecall:\")\n",
    "    print(recall_score(Y_test, Y_pred, pos_label = \"positive\"))\n",
    "    print(\"\\nf1:\")\n",
    "    print(f1_score(Y_test, Y_pred, pos_label = \"positive\") ) \n",
    "    return accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "I've tried a couple of classifiers here: SVM, RandomForests, XGBoost.\n",
    "\n",
    "Best results were from XGBoost. For current (example) features you could get:\n",
    "\n",
    "|Type of classifier|F1 score|recall|\n",
    "|------------------|--------|------|\n",
    "|RandomForests|0.7|0.56|\n",
    "|XGBoost (vanilla)|0.82|0.74|\n",
    "|XGBoost (optimised)*|0.876|0.80|\n",
    "\n",
    "\n",
    "`*` See below parameters for optimised version\n",
    "\n",
    "For production model I've got F1 score = 0.917 wih recall = 0.88 (with help of [visual debugging, see here](visually_debug_model.ipynb) ). Not a record, but quite enough for my purposes.\n",
    "\n",
    "Below is optimised parameter set for XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['versions/xgb_model.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "\n",
    "\n",
    "clf = XGBClassifier( learning_rate =0.01,\n",
    "                     n_estimators=5000,\n",
    "                     max_depth=4,\n",
    "                     min_child_weight=6,\n",
    "                     gamma=0,\n",
    "                     subsample=0.8,\n",
    "                     colsample_bytree=0.8,\n",
    "                     reg_alpha=0.005,\n",
    "                     objective= 'binary:logistic',\n",
    "                     nthread=7,\n",
    "                     scale_pos_weight=1,seed=27\n",
    "                   )\n",
    "\n",
    "\n",
    "clf.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# to save a model, uncomment this\n",
    "# joblib.dump(clf, 'versions/xgb_model.pkl')\n",
    "\n",
    "# you can load actual production model from this file, uncomment line below:\n",
    "# clf = joblib.load( 'versions/xgb_model_v003.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Performance\n",
      "Accuracy = 0.96%.\n",
      "[[277   2]\n",
      " [ 13  53]]\n",
      "\n",
      "precision:\n",
      "0.9636363636363636\n",
      "\n",
      "recall:\n",
      "0.803030303030303\n",
      "\n",
      "f1:\n",
      "0.8760330578512396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9565217391304348"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "Y_pred = clf.predict(X_test) \n",
    "evaluate(Y_test, Y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next step: actual search \n",
    "Now, we have trained model and could search for satellite images with amber mining. [See Step 3](step3.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
